{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANGCHAIN SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription: code file to get required JSONs for various applications using Open AI large language models\\n\\nHow-to-use:\\n1. replace the following variables for your use case\\n    - sample_app_description\\n    - sample_user_messages\\n    - supported_animal_list\\n    - json_examples\\n    - json_key_value_descriptions\\n2. change the variables & description in json_schema_generation_prompt_template\\n3. replace the variables in values dict in main() function\\n4. pip install openai, langchain\\n5. python3 main.py\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description: code file to get required JSONs for various applications using Open AI large language models\n",
    "\n",
    "How-to-use:\n",
    "1. replace the following variables for your use case\n",
    "    - sample_app_description\n",
    "    - sample_user_messages\n",
    "    - supported_animal_list\n",
    "    - json_examples\n",
    "    - json_key_value_descriptions\n",
    "2. change the variables & description in json_schema_generation_prompt_template\n",
    "3. replace the variables in values dict in main() function\n",
    "4. pip install openai, langchain\n",
    "5. python3 main.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for application\n",
    "\n",
    "sample_app_description = \"an app which shares bed time stories along with images of animals if mentioned by the user if supported\"\n",
    "\n",
    "sample_user_messages = [\n",
    "    \"tell my daughter Lilly a story about frog & snail who were friends in school\",\n",
    "    \"tell my son a story about animals in a jungle\",\n",
    "    \"tell me a story about the king of the jungle\",\n",
    "    \"what happened with rabbit and tortoise in their race? complete the story, my son is listening to you during bedtime\"\n",
    "]\n",
    "\n",
    "supported_animal_list = [\"lion\", \"snail\", \"monkey\", \"tiger\", \"elephant\", \"giraffe\", \"zebra\", \"hippopotamus\",\n",
    "                         \"kangaroo\", \"penguin\", \"bear\", \"wolf\", \"fox\", \"rhinoceros\", \"jaguar\", \"deer\", \"eagle\", \"hawk\", \"owl\", \"buffalo\"]\n",
    "\n",
    "json_examples = [\n",
    "    {\n",
    "        \"is_this_request_asking_to_recite_a_story\": True,\n",
    "        \"animals_mentioned\": [\"frog\", \"snail\"]\n",
    "    },\n",
    "    {\n",
    "        \"is_this_request_asking_to_recite_a_story\": False,\n",
    "        \"animals_mentioned\": []\n",
    "    },\n",
    "    {\n",
    "        \"is_this_request_asking_to_recite_a_story\": True,\n",
    "        \"animals_mentioned\": []\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_key_value_descriptions = {\n",
    "    \"is_this_request_asking_to_recite_a_story\": \"when the user's message is asking to share a story\",\n",
    "    \"animals_mentioned\": \"this will be empty list when user has not mentioned any animals which fall under supported_animals_list otherwise this will be a list with animals mentioned by the user, this list should contain that animal's corresponding key in the supported_animal_list\"\n",
    "}\n",
    "\n",
    "json_schema_generation_prompt_template = \"\"\"\n",
    "given a user's message below, your task is to create a JSON response adhering to the JSON schema shared below.\n",
    "\n",
    "user_message: {user_message}\n",
    "supported_animal_list: {supported_animal_list}\n",
    "JSON Schema: {json_schema_string}\n",
    "\n",
    "Instructions\n",
    "- your response should be formatted as a JSON instance that conforms to the provided JSON schema\n",
    "- analyze the user_message carefully above to extract the necessary information needed to populate the JSON\n",
    "- set the fileds in JSON based on the user_message & following mentioned descroption of keys\n",
    "{json_key_value_descriptions}\n",
    "\n",
    "return the required JSON schema from next line:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "TEMPERATURE = 0.0\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "MAX_RETRIES_COUNT = 2\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('main.log', mode='w')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function validates the input json\n",
    "\n",
    "def validate_json_examples(json_examples: list):\n",
    "    expected_keys = json_examples[0].keys()\n",
    "    expected_types = {key: type(json_examples.get(key))\n",
    "                      for key, val in json_examples[0].items()}\n",
    "\n",
    "    for json_object in json_examples:\n",
    "        keys = set(json_object.keys())\n",
    "        if (keys != expected_keys):\n",
    "            logger.error(\"inconsistent json examples - check the keys\")\n",
    "            return False\n",
    "\n",
    "        for key, val in json_object:\n",
    "            if type(val) != expected_types.get(key):\n",
    "                logger.error(\"inconsistent json examples - check values\")\n",
    "                return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this function basically defines the data formats???\n",
    "\n",
    "def generate_json_schema(json_example):\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {}\n",
    "    }\n",
    "\n",
    "    for key, value in json_example.items():\n",
    "        if value is None:\n",
    "            schema[\"properties\"][key] = {\n",
    "                \"type\": \"null\"\n",
    "            }\n",
    "        elif isinstance(value, bool):\n",
    "            schema[\"properties\"][key] = {\n",
    "                \"type\": \"boolean\"\n",
    "            }\n",
    "        elif isinstance(value, list):\n",
    "            if all(isinstance(i, dict) for i in value):\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": generate_json_schema(value[0]) if value else {\"type\": \"object\"}\n",
    "                }\n",
    "            elif all(isinstance(i, str) for i in value):\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"}\n",
    "                }\n",
    "            elif all(isinstance(i, (int, float)) for i in value):\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"number\"}\n",
    "                }\n",
    "            else:\n",
    "                schema[\"properties\"][key] = {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"object\"}\n",
    "                }\n",
    "        elif isinstance(value, str):\n",
    "            schema[\"properties\"][key] = {\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        elif isinstance(value, int):\n",
    "            schema[\"properties\"][key] = {\n",
    "                \"type\": \"integer\"\n",
    "            }\n",
    "        elif isinstance(value, float):\n",
    "            schema[\"properties\"][key] = {\n",
    "                \"type\": \"number\"\n",
    "            }\n",
    "        elif isinstance(value, dict):\n",
    "            schema[\"properties\"][key] = generate_json_schema(value)\n",
    "        else:\n",
    "            schema[\"properties\"][key] = {\n",
    "                \"type\": \"object\"\n",
    "            }\n",
    "\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets the response of the LLM\n",
    "\n",
    "def get_output_from_OpenAI(prompt_template: str, values: dict):\n",
    "    llm = ChatOpenAI(temperature=TEMPERATURE, model=MODEL_NAME,\n",
    "                     openai_api_key=OPENAI_API_KEY)\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=PromptTemplate.from_template(prompt_template)\n",
    "    )\n",
    "    llm_output = llm_chain.apply([values])[0]['text']\n",
    "    return llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this function validates the format of the JSON responses based on the created schema from generate_json_schema function???\n",
    "\n",
    "def lint_json(response, json_examples):\n",
    "    sample_json_object = json_examples[0]\n",
    "    schema_sample_json_object = generate_json_schema(\n",
    "        json_example=sample_json_object)\n",
    "    schema_response = generate_json_schema(json_example=response)\n",
    "\n",
    "    logger.info(\"schema_sample_json_object: {}\".format(\n",
    "        schema_sample_json_object))\n",
    "    logger.info(\"schema_response: {}\".format(schema_response))\n",
    "\n",
    "    return schema_sample_json_object == schema_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function for identifying the type of error\n",
    "\n",
    "def get_error_in_response(response):\n",
    "    if (isinstance(response, dict)):\n",
    "        is_valid_json = lint_json(response, json_examples=json_examples)\n",
    "        if (is_valid_json):\n",
    "            logger.info(\"json response has been created successfully\")\n",
    "            return None\n",
    "        else:\n",
    "            logger.debug(\n",
    "                \"incorrect json-values returned by the LLM. output: {}\".format(response))\n",
    "            return \"KeyValueError\"\n",
    "    else:\n",
    "        try:\n",
    "            response = json.loads(response)\n",
    "            is_valid_json = lint_json(response, json_examples=json_examples)\n",
    "            if (is_valid_json):\n",
    "                logger.info(\"json response has been created successfully\")\n",
    "                return None\n",
    "            else:\n",
    "                logger.debug(\n",
    "                    \"incorrect json-values returned by the LLM. output: {}\".format(response))\n",
    "                return \"KeyValueError\"\n",
    "        except Exception as e:\n",
    "            logger.debug(\n",
    "                \"incorrect json-string returned by the LLM. output: {}\".format(response))\n",
    "            return \"JsonTextError\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the actual response of the LLM\n",
    "\n",
    "def extract_json_from_response(response):\n",
    "\n",
    "    if (isinstance(response, dict)):\n",
    "        return response\n",
    "\n",
    "    logger.debug(\"trying to extract json (if any) by finding first { & last }\")\n",
    "    first_brace_index = response.find(\"{\")\n",
    "    last_brace_index = response.rfind(\"}\")\n",
    "\n",
    "    response = response[first_brace_index:last_brace_index+1]\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "def generate_required_json(prompt_template: str, values: dict, retry_count: int):\n",
    "    response = get_output_from_OpenAI(\n",
    "        prompt_template=prompt_template, values=values)\n",
    "    error = get_error_in_response(response=response)\n",
    "\n",
    "    if not error:\n",
    "        return response\n",
    "    else:\n",
    "        response = extract_json_from_response(response)\n",
    "        error = get_error_in_response(response)\n",
    "        if not error:\n",
    "            return response\n",
    "        elif error == \"JsonTextError\":\n",
    "            response = extract_json_from_response(response=response)\n",
    "            error = get_error_in_response(response=response)\n",
    "            if not error:\n",
    "                return response\n",
    "            else:\n",
    "                pass\n",
    "        elif error == \"KeyValueError\":\n",
    "            retry_count += 1\n",
    "            if (retry_count < MAX_RETRIES_COUNT):\n",
    "                response = generate_required_json(\n",
    "                    prompt_template=prompt_template, values=values, retry_count=retry_count)\n",
    "            else:\n",
    "                logger.error(\n",
    "                    \"was not able to generate JSON output from the LLM for given user message. final response: {}\".format(response))\n",
    "                return None\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the main which ties all the functions together\n",
    "\n",
    "def main():\n",
    "    user_message = sample_user_messages[0]\n",
    "    json_example = json_examples[0]\n",
    "    schema = generate_json_schema(json_example=json_example)\n",
    "    json_schema_string = json.dumps(schema, indent=2)\n",
    "    values = {\n",
    "        \"user_message\": user_message,\n",
    "        \"supported_animal_list\": supported_animal_list,\n",
    "        \"json_schema_string\": json_schema_string,\n",
    "        \"json_key_value_descriptions\": json_key_value_descriptions\n",
    "    }\n",
    "\n",
    "    response = generate_required_json(\n",
    "        prompt_template=json_schema_generation_prompt_template, values=values, retry_count=0)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"is_this_request_asking_to_recite_a_story\": true,\n",
      "  \"animals_mentioned\": [\"frog\", \"snail\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
